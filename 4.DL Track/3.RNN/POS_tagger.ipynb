{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging - An Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of classifying words into their __parts of speech__ and labeling them accordingly is known as **part-of-speech tagging**, or simply **POS-tagging**.\n",
    "\n",
    "The NLTK library has a number of corpora which contains word and its POS tag. The following table provide information about each tag:\n",
    "\n",
    "![POS tags](./jupyter resources/pos_tagging.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook layout\n",
    "1. Preprocess data\n",
    "2. Vanilla RNN\n",
    "3. Word Embeddings\n",
    "4. LSTM\n",
    "5. GRU\n",
    "6. Bidirectional LSTM\n",
    "7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\91975\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\91975\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\91975\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91975\\anaconda3\\lib\\site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in c:\\users\\91975\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: keras in c:\\users\\91975\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\91975\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\91975\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\91975\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp38-cp38-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.1.0\n",
      "Requirement already satisfied: seaborn in c:\\users\\91975\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from seaborn) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from seaborn) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91975\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install keras\n",
    "!pip install gensim\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\91975\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\91975\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\91975\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\91975\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "# load POS tagged corpora from NLTK\n",
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', '.'),\n",
       " ('We', 'PRON'),\n",
       " ('have', 'VERB'),\n",
       " ('no', 'DET'),\n",
       " ('useful', 'ADJ'),\n",
       " ('information', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('whether', 'ADP'),\n",
       " ('users', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('risk', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('said', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('James', 'NOUN'),\n",
       " ('A.', 'NOUN'),\n",
       " ('Talcott', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Boston', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('Dana-Farber', 'NOUN'),\n",
       " ('Cancer', 'NOUN'),\n",
       " ('Institute', 'NOUN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the data\n",
    "tagged_sentences[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data in words (X) and tags (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a **many-to-many** problem, each data point will be a different sentence of the corpora.\n",
    "\n",
    "Each data point will have multiple words in the **input sequence**. This is what we will refer to as **X**.\n",
    "\n",
    "Each word will have its correpsonding tag in the **output sequence**. This what we will refer to as **Y**.\n",
    "\n",
    "Sample dataset:\n",
    "\n",
    "|                    X                        |                 Y                |\n",
    "|---------------------------------------------|----------------------------------|\n",
    "|   Mr. Vinken is chairman of Elsevier        |   NOUN NOUN VERB NOUN ADP NOUN   |\n",
    "|     We have no useful information           |      PRON VERB DET ADJ NOUN      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # store input sequence\n",
    "Y = [] # store output sequence\n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0])  # entity[0] contains the word\n",
    "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
    "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tagged sentences: 72202\n",
      "Vocabulary size: 59448\n",
      "Total number of tags: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
    "print(\"Vocabulary size: {}\".format(num_words))\n",
    "print(\"Total number of tags: {}\".format(num_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "sample Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at first data point\n",
    "# this is one data point that will be fed to the RNN\n",
    "print('sample X: ', X[0], '\\n')\n",
    "print('sample Y: ', Y[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of first input sequence  : 18\n",
      "Length of first output sequence : 18\n"
     ]
    }
   ],
   "source": [
    "# In this many-to-many problem, the length of each input and output sequence must be the same.\n",
    "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\n",
    "print(\"Length of first input sequence  : {}\".format(len(X[0])))\n",
    "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorise X and Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode X and Y to integer values\n",
    "\n",
    "We'll use the Tokenizer() function from Keras library to encode text sequence to integer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode X\n",
    "\n",
    "word_tokenizer = Tokenizer()                      # instantiate tokeniser\n",
    "word_tokenizer.fit_on_texts(X)                    # fit tokeniser on data\n",
    "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode Y\n",
    "\n",
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tag_tokenizer.texts_to_sequences(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Raw data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
      "\n",
      "\n",
      "** Encoded data point ** \n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "X:  [6423, 24231, 2, 7652, 102, 170, 2, 47, 1898, 1, 269, 17, 7, 13230, 619, 1711, 2761, 3] \n",
      "\n",
      "Y:  [1, 1, 3, 11, 1, 6, 3, 2, 2, 5, 1, 4, 5, 6, 1, 1, 11, 3] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at first encoded data point\n",
    "\n",
    "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X[0], '\\n')\n",
    "print('Y: ', Y[0], '\\n')\n",
    "print()\n",
    "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
    "print('X: ', X_encoded[0], '\\n')\n",
    "print('Y: ', Y_encoded[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentences have disparate input-output lengths.\n"
     ]
    }
   ],
   "source": [
    "# make sure that each sequence of input and output is same length\n",
    "\n",
    "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded, Y_encoded)]\n",
    "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step after encoding the data is to **define the sequence lengths**. As of now, the sentences present in the data are of various lengths. We need to either pad short sentences or truncate long sentences to a fixed length. This fixed length, however, is a **hyperparameter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 271\n"
     ]
    }
   ],
   "source": [
    "# check length of longest sentence\n",
    "lengths = [len(seq) for seq in X_encoded]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANH0lEQVR4nO3df2jc9R3H8de7ubPT1aFNbW3TuugiiP+4uVAoG+IfujX5x+0Pwb/MH4OCbCETBjrSkEQCssEGkj9aOjaIY0yUbcw/krA6BtNE1qUj1Wp1ni7SpL+Sy1nN2iR318/+yCVL01zukt733r3r8wEhyfe+9/18Pv3o08s3V7QQggAA5bfJewIAcLMiwADghAADgBMCDABOCDAAOImt5+Rt27aF+vr6iKYCANXp+PHjUyGEu1YeX1eA6+vrNTIyUrpZAcBNwMw+Xe04tyAAwAkBBgAnBBgAnBBgAHBCgAHACQEGACcEGACcEGAAcEKAAcAJAQYAJwQYAJwQYABwQoABwAkBBgAnBBgAnBBgAHBCgAHACQEGACcEGACcrOv/CVcuvb29SiQSeR+fmJiQJNXV1RW8VkNDg1pbW0s2NwAolRsywIlEQqMnTyl729ZVH6+5dFGSdG5u7enXXJou+dwAoFRuyABLUva2rbr8QPOqj936Qb8k5X185XkAcCPiHjAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4KUuAe3t71dvbW46h3NwMawRQWrFyDJJIJMoxjKubYY0ASotbEADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgJOY9wSqzaOPPlq2sWKxmDKZzJrn7N27V8eOHVs6v6amRvF4XDMzM7rjjjt08OBBdXR0aOfOnZKk06dPK51O6+6779b09LTm5+fV2dmpPXv26JlnnlE6nVY8Htfu3bsVi8VkZqqpqdGTTz6pnp4edXR06NVXX1Umk1E2m9WZM2d0zz336MUXX1Rtba2SyaSee+45jY+Pa/v27ZqcnFRPT4/6+vrU2dkpSero6FAIQT09PZKk7u5udXZ2qra2tuCfSTKZXDo/lUqpra1NL7zwgg4dOqTx8XHt2rVLmzdvVk9PT1HXKzRGsdco5jkbuS6iF+W+1HR1dRV98pEjR7oOHDiw7kEGBwclSU1NTUWffzb1X2W23b/q4/GpjyQp7+PLz9t155aix70ei2s8f/585GMtunLlSsFzJiYmrjo/m81qfn5ekjQ7O6vh4WFdunRJqVRKqVRq6ZozMzPKZrOSpKGhIY2Ojmp6enrpOp999pmmp6eVTCY1NTWloaEhZbNZDQ0N6cKFC5qenlYqlVImk1EymdTc3Jz27dunw4cP6+2331Ymk9HFixeVyWQ0PDys8fFxzc7OanR0VG+99ZampqY0Nzen0dFRvfnmm5qdndW+ffsKrvfw4cNL57/22muanJzU8PCwzp07p0wmo1QqtXTtYq5XaIxir1HMczZyXUSvFPvS3d19tqur68jK49yCKKETJ054T2HdZmZmCp6TyWQ0NjZW8Jzln1fq7+9XIpFQf3//qnMIIWhgYEADAwNXPWdgYEAhBA0ODiqZTK45h2QyqcHBQYUQ1N/fvzTn1dY4MDBQ8HqFxihmTsU+ZyPXRfSi3pey3IKYmJjQ5cuX1dbWVtT5iURCm+bDdY+7afZzJRJfFD3u9UgkEpGPUcnS6bR6enrWvGWSTqcVQrjqezOTJGWzWb388st69tln8z6/r69v6RV8Op0uOJ9C1ys0RjFzKvY5G7kuohf1vhR8BWxmB8xsxMxGJicnSzYwbj6FXkUvj+/KY5lMRkePHl3z+W+88UbBe+LLr1voeoXGKGZOxT5nI9dF9KLel4KvgEMIRyQdkaTGxsYNvSytq6uTJL300ktFnd/W1qbjn1z/vdQrX/qKGu7bUfS416Otra0ib0GUU319/ZoRNrNrIrx4LBaL6fHHH1/z+o899pj6+/uLirCZFbxeoTGKmVOxz9nIdRG9qPeFe8Aoi3g8roMHDyoWy//f/Hg8rng8ftX3i+fX1NTo6aefXnOMlpYWbdq0aem5heZT6HqFxihmTsU+ZyPXRfSi3hcCXEIPPfSQ9xTWbcuWLQXPicViqq+vL3jO8s8rNTc3q6GhQc3NzavOwczU1NR01TtWmpub1dTUJDPT/v37C74FqLa2Vvv375eZqbm5eWnOq62xqalpQ28pWj5GMXMq9jkbuS6iF/W+8D7gClau9wG3t7cX/T7g9vb2Vd8HvPjKoaWlRe+///5V7wPu7u5WX1/f0jmJREIhhKXvx8bGin7l0dLSsnT+4vuAu7u7r3kf8PW8klk+Rimfs5HrInpR7out9ouPfBobG8PIyMi6B1l8F8J67wFffuDaV0uSdOsHC29lyvf48vO+WcZ7wFLxawRw8zCz4yGExpXHuQUBAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4iZVjkIaGhnIM4+pmWCOA0ipLgFtbW8sxjKubYY0ASotbEADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOIl5TyCfmkvTuvWD/jyPJSUp7+PLryHtKPXUAKAkbsgANzQ0rPn4xERGklRXVyiuOwpeCwC83JABbm1t9Z4CAESOe8AA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOCHAAOCEAAOAEwIMAE4IMAA4IcAA4IQAA4ATAgwATggwADghwADghAADgBMCDABOCDAAOLEQQvEnm01K+nQD42yTNLWB51WKal+fVP1rZH2V70Ze41dDCHetPLiuAG+UmY2EEBojH8hJta9Pqv41sr7KV4lr5BYEADghwADgpFwBPlKmcbxU+/qk6l8j66t8FbfGstwDBgBci1sQAOCEAAOAk0gDbGb7zexDM0uY2fNRjlVOZjZmZu+a2aiZjeSObTWzo2b2Ue7znd7zLJaZ/cbMLpjZyWXH8q7HzH6a29MPzey7PrMuXp71dZnZRG4PR82sedljlba+PWb2NzM7ZWbvmVlb7ng17WG+NVb2PoYQIvmQVCPpY0n3SbpF0glJD0Y1Xjk/JI1J2rbi2M8lPZ/7+nlJP/Oe5zrW84ikhyWdLLQeSQ/m9nKzpHtze1zjvYYNrK9L0k9WObcS17dT0sO5r2+X9O/cOqppD/OtsaL3McpXwHslJUIIn4QQ5iW9IumJCMfz9oSkvtzXfZK+5ziXdQkh/F3S9IrD+dbzhKRXQghzIYT/SEpoYa9vWHnWl08lru9sCOFfua+/kHRKUp2qaw/zrTGfilhjlAGuk3R62ffjWvsPrJIESX8xs+NmdiB3bEcI4ay08A+LpO1usyuNfOuppn39kZm9k7tFsfjjeUWvz8zqJX1D0j9UpXu4Yo1SBe9jlAG2VY5Vy3vevhVCeFhSk6Qfmtkj3hMqo2rZ10OSvibp65LOSvpF7njFrs/Mtkj6g6QfhxA+X+vUVY5V6horeh+jDPC4pD3Lvt8t6UyE45VNCOFM7vMFSX/Swo82581spyTlPl/wm2FJ5FtPVexrCOF8CCEbQrgi6Vf6/4+nFbk+M4trIUy/CyH8MXe4qvZwtTVW+j5GGeB/SrrfzO41s1skPSXp9QjHKwsz+7KZ3b74taTvSDqphbW15E5rkfRnnxmWTL71vC7pKTPbbGb3Srpf0jGH+V2XxTDlfF8LeyhV4PrMzCT9WtKpEMIvlz1UNXuYb40Vv48R/+ayWQu/rfxYUrv3bxxLtKb7tPDb1ROS3ltcl6RaSX+V9FHu81bvua5jTb/Xwo9vaS28cvjBWuuR1J7b0w8lNXnPf4Pr+62kdyW9o4V/WXdW8Pq+rYUfr9+RNJr7aK6yPcy3xoreR/4qMgA44W/CAYATAgwATggwADghwADghAADgBMCDABOCDAAOPkfBSbTSsSEeUoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad each sequence to MAX_SEQ_LENGTH using KERAS' pad_sequences() function. \n",
    "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
    "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
    "\n",
    "# Truncation and padding can either be 'pre' or 'post'. \n",
    "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
    "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
    "\n",
    "MAX_SEQ_LENGTH = 100  # sequences greater than 100 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0  6423 24231\n",
      "     2  7652   102   170     2    47  1898     1   269    17     7 13230\n",
      "   619  1711  2761     3] \n",
      "\n",
      "\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  1  1  3 11  1  6  3  2  2  5  1  4  5  6\n",
      "  1  1 11  3]\n"
     ]
    }
   ],
   "source": [
    "# print the first sequence\n",
    "print(X_padded[0], \"\\n\"*3)\n",
    "print(Y_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RNN will learn the zero to zero mapping while training. So we don't need to worry about the padded zeroes. Please note that zero is not reserved for any word or tag, it's only reserved for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign padded sequences to X and Y\n",
    "X, Y = X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, each word and each tag is encoded as an integer. \n",
    "\n",
    "We'll use a more sophisticated technique to represent the input words (X) using what's known as **word embeddings**.\n",
    "\n",
    "However, to represent each tag in Y, we'll simply use **one-hot encoding** scheme since there are only 13 tags in the dataset and the LSTM will have no problems in learning its own representation of these tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use word embeddings, you can go for either of the following models:\n",
    "1. word2vec model: https://code.google.com/archive/p/word2vec/\n",
    "2. GloVe model : https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "We're using the word2vec model for no particular reason. Both of these are very efficient in representing words. You can try both and see which one works better.\n",
    "\n",
    "Dimensions of a word embedding is: (VOCABULARY_SIZE, EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use word embeddings for input sequences (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'word-embeddings/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b0e7ecba7f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# load word2vec using the following function present in the gensim library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mword2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m         \"\"\"\n\u001b[1;32m-> 1630\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1631\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1891\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1892\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1894\u001b[0m             \u001b[1;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mso_compression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0msubmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\local_file.py\u001b[0m in \u001b[0;36mopen_uri\u001b[1;34m(uri_as_string, mode, transport_params)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mparsed_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uri_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'word-embeddings/GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "# word2vec download link (Size ~ 1.5GB): https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "path = 'word-embeddings/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "# load word2vec using the following function present in the gensim library\n",
    "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d34054f5b130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# word2vec effectiveness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"King\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Woman\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Man\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "# word2vec effectiveness\n",
    "word2vec.most_similar(positive = [\"King\", \"Woman\"], negative = [\"Man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ee798a076d6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0membedding_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "# assign word vectors from word2vec model\n",
    "\n",
    "EMBEDDING_SIZE  = 300  # each word in word2vec model is represented using a 300 dimensional vector\n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "# create an empty embedding matix\n",
    "embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))\n",
    "\n",
    "# create a word to index dictionary mapping\n",
    "word2id = word_tokenizer.word_index\n",
    "\n",
    "# copy vectors from word2vec model to the words present in corpus\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = word2vec[word]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (59449, 300)\n"
     ]
    }
   ],
   "source": [
    "# check embedding dimension\n",
    "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at an embedding of a word\n",
    "embedding_weights[word_tokenizer.word_index['joy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use one-hot encoding for output sequences (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras' to_categorical function to one-hot encode Y\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72202, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "# print Y of the first output sequqnce\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in training, validation and tesing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split entire data into training and testing sets\n",
    "TEST_SIZE = 0.15\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation sets\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=VALID_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Shape of input sequences: (52165, 100)\n",
      "Shape of output sequences: (52165, 100, 13)\n",
      "--------------------------------------------------\n",
      "VALIDATION DATA\n",
      "Shape of input sequences: (9206, 100)\n",
      "Shape of output sequences: (9206, 100, 13)\n",
      "--------------------------------------------------\n",
      "TESTING DATA\n",
      "Shape of input sequences: (10831, 100)\n",
      "Shape of output sequences: (10831, 100, 13)\n"
     ]
    }
   ],
   "source": [
    "# print number of samples in each set\n",
    "print(\"TRAINING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_train.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_train.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"VALIDATION DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_validation.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_validation.shape))\n",
    "print(\"-\"*50)\n",
    "print(\"TESTING DATA\")\n",
    "print('Shape of input sequences: {}'.format(X_test.shape))\n",
    "print('Shape of output sequences: {}'.format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using RNN, we must make sure the dimensions of the data are what an RNN expects. In general, an RNN expects the following shape\n",
    "\n",
    "Shape of X:\n",
    "(#samples, #timesteps, #features)\n",
    "\n",
    "Shape of Y:\n",
    "(#samples, #timesteps, #features)\n",
    "\n",
    "![RNN tensor shape](./jupyter resources/rnn_tensor.png)\n",
    "\n",
    "Now, there can be various variations in the shape that you use to feed an RNN depending on the type of architecture. Since the problem we're working on has a many-to-many architecture, the input and the output both include number of timesteps which is nothing but the sequence length. But notice that the tensor X doesn't have the third dimension, that is, number of features. That's because we're going to use word embeddings before feeding in the data to an RNN, and hence there is no need to explicitly mention the third dimension. That's because when you use the Embedding() layer in Keras, you the training data will automatically be converted to (#samples, #timesteps, #features) where #features will be the embedding dimention (and note that the Embedding layer is always the very first layer of an RNN). While using the embedding layer we only need to reshape the data to (#samples, #timesteps) which is what we have done. However, note that you'll need to shape it to (#samples, #timesteps, #features) in case you don't use the Embedding() layer in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninitialised fixed embeddings\n",
    "First let's try running a vanilla RNN. For this RNN we won't use the pre-trained word embeddings. We'll use randomly inititalised embeddings. Moreover, we won't update the embeddings weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of tags\n",
    "NUM_CLASSES = Y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          17834700  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100, 64)           23360     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 100, 13)           845       \n",
      "=================================================================\n",
      "Total params: 17,858,905\n",
      "Trainable params: 24,205\n",
      "Non-trainable params: 17,834,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "408/408 [==============================] - 69s 131ms/step - loss: 0.7247 - acc: 0.8246 - val_loss: 0.3508 - val_acc: 0.8928\n",
      "Epoch 2/10\n",
      "408/408 [==============================] - 50s 123ms/step - loss: 0.3190 - acc: 0.9021 - val_loss: 0.2444 - val_acc: 0.9251\n",
      "Epoch 3/10\n",
      "408/408 [==============================] - 46s 114ms/step - loss: 0.2322 - acc: 0.9284 - val_loss: 0.1981 - val_acc: 0.9366\n",
      "Epoch 4/10\n",
      "408/408 [==============================] - 36s 87ms/step - loss: 0.1922 - acc: 0.9384 - val_loss: 0.1712 - val_acc: 0.9446\n",
      "Epoch 5/10\n",
      "408/408 [==============================] - 47s 115ms/step - loss: 0.1677 - acc: 0.9459 - val_loss: 0.1541 - val_acc: 0.9502\n",
      "Epoch 6/10\n",
      "408/408 [==============================] - 52s 129ms/step - loss: 0.1514 - acc: 0.9509 - val_loss: 0.1427 - val_acc: 0.9532\n",
      "Epoch 7/10\n",
      "408/408 [==============================] - 51s 126ms/step - loss: 0.1417 - acc: 0.9536 - val_loss: 0.1346 - val_acc: 0.9552\n",
      "Epoch 8/10\n",
      "408/408 [==============================] - 44s 108ms/step - loss: 0.1330 - acc: 0.9558 - val_loss: 0.1296 - val_acc: 0.9570\n",
      "Epoch 9/10\n",
      "408/408 [==============================] - 55s 135ms/step - loss: 0.1290 - acc: 0.9568 - val_loss: 0.1253 - val_acc: 0.9576\n",
      "Epoch 10/10\n",
      "408/408 [==============================] - 55s 134ms/step - loss: 0.1250 - acc: 0.9579 - val_loss: 0.1221 - val_acc: 0.9586\n"
     ]
    }
   ],
   "source": [
    "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninitialised trainable embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  True                     # True - update the embeddings while training\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-trained embedding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        weights       = [embedding_weights],      # word embedding matrix\n",
    "                        trainable     =  True                     # True - update the embeddings while training\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check summary of the model\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(rnn_training.history['acc'])\n",
    "plt.plot(rnn_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use pre-trained word embeddings in following models and allow them to be updated as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim     = VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                         output_dim    = EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                         input_length  = MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                         weights       = [embedding_weights],     # word embedding matrix\n",
    "                         trainable     = True                     # True - update embeddings_weight matrix\n",
    "))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss      =  'categorical_crossentropy',\n",
    "                   optimizer =  'adam',\n",
    "                   metrics   =  ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of the model\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_training = lstm_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(lstm_training.history['acc'])\n",
    "plt.plot(lstm_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                        output_dim    = EMBEDDING_SIZE,\n",
    "                        input_length  = MAX_SEQ_LENGTH,\n",
    "                        weights       = [embedding_weights],\n",
    "                        trainable     = True\n",
    "))\n",
    "gru_model.add(GRU(64, return_sequences=True))\n",
    "gru_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of model\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_training = gru_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(gru_training.history['acc'])\n",
    "plt.plot(gru_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "\n",
    "bidirect_model = Sequential()\n",
    "bidirect_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                             output_dim    = EMBEDDING_SIZE,\n",
    "                             input_length  = MAX_SEQ_LENGTH,\n",
    "                             weights       = [embedding_weights],\n",
    "                             trainable     = True\n",
    "))\n",
    "bidirect_model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "bidirect_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check summary of model\n",
    "bidirect_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_training = bidirect_model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise training history\n",
    "plt.plot(bidirect_training.history['acc'])\n",
    "plt.plot(bidirect_training.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = rnn_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = lstm_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = gru_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = bidirect_model.evaluate(X_test, Y_test, verbose = 1)\n",
    "print(\"Loss: {0},\\nAccuracy: {1}\".format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
