{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation using RNN - Character Level\n",
    "\n",
    "To generate text using RNN, we need a to convert raw text to a supervised learning problem format.\n",
    "\n",
    "Take, for example, the following corpus:\n",
    "\n",
    "\"Her brother shook his head incredulously\"\n",
    "\n",
    "First we need to divide the data into tabular format containing input (X) and output (y) sequences. In case of a character level model, the X and y will look like this:\n",
    "\n",
    "|      X     |  Y  |\n",
    "|------------|-----|\n",
    "|    Her b   |  r  |\n",
    "|    er br   |  o  |\n",
    "|    r bro   |  t  |\n",
    "|     brot   |  h  |\n",
    "|    broth   |  e  |\n",
    "|    .....   |  .  |\n",
    "|    .....   |  .  |\n",
    "|    ulous   |  l  |\n",
    "|    lousl   |  y  |\n",
    "\n",
    "Note that in the above problem, the sequence length of X is five characters and that of y is one character. Hence, this is a many-to-one architecture. We can, however, change the number of input characters to any number of characters depending on the type of problem.\n",
    "\n",
    "A model is trained on such data. To generate text, we simply give the model any five characters using which it predicts the next character. Then it appends the predicted character to the input sequence (on the extreme right of the sequence) and discards the first character (character on extreme left of the sequence). Then it predicts again using the new sequence and the cycle continues until a fix number of iterations. An example is shown below:\n",
    "\n",
    "Seed text: \"incre\"\n",
    "\n",
    "|      X                                            |  Y                       |\n",
    "|---------------------------------------------------|--------------------------|\n",
    "|                        incre                      |    < predicted char 1 >  |\n",
    "|               ncre < predicted char 1 >              |    < predicted char 2 >  |\n",
    "|       cre< predicted char 1 > < predicted char 2 >   |    < predicted char 3 >  |\n",
    "|       re< predicted char 1 >< predicted char 2 > < predicted char 3 >   |    < predicted char 4 >  |\n",
    "|                      ...                          |            ...           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "1. Preprocess data\n",
    "2. LSTM model\n",
    "3. Generate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Sa28LJ6YqdD",
    "outputId": "ae782caf-f9d1-43fe-aa32-4f2ccf02cfe0"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a C code generator by training an RNN on a huge corpus of C code (the linux kernel code). You can download the C code used as source text from the following link:\n",
    "https://github.com/torvalds/linux/tree/master/kernel\n",
    "\n",
    "We have already downloaded the entire kernel folder and stored in a local directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "hO1StR3rX72I",
    "outputId": "42079a21-0a71-4fba-c90a-b13e3acbb909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitignore', 'acct.c', 'async.c', 'audit.c', 'audit.h', 'auditfilter.c', 'auditsc.c', 'audit_fsnotify.c', 'audit_tree.c', 'audit_watch.c', 'backtracetest.c', 'bounds.c', 'bpf', 'capability.c', 'cfi.c', 'cgroup', 'compat.c', 'configs', 'configs.c', 'context_tracking.c', 'cpu.c', 'cpu_pm.c', 'crash_core.c', 'crash_dump.c', 'cred.c', 'debug', 'delayacct.c', 'dma', 'dma.c', 'entry', 'events', 'exec_domain.c', 'exit.c', 'extable.c', 'fail_function.c', 'fork.c', 'freezer.c', 'futex.c', 'gcov', 'gen_kheaders.sh', 'groups.c', 'hung_task.c', 'iomem.c', 'irq', 'irq_work.c', 'jump_label.c', 'kallsyms.c', 'kcmp.c', 'Kconfig.freezer', 'Kconfig.hz', 'Kconfig.locks', 'Kconfig.preempt', 'kcov.c', 'kcsan', 'kexec.c', 'kexec_core.c', 'kexec_elf.c', 'kexec_file.c', 'kexec_internal.h', 'kheaders.c', 'kmod.c', 'kprobes.c', 'ksysfs.c', 'kthread.c', 'latencytop.c', 'livepatch', 'locking', 'Makefile', 'module-internal.h', 'module.c', 'module_signature.c', 'module_signing.c', 'notifier.c', 'nsproxy.c', 'padata.c', 'panic.c', 'params.c', 'pid.c', 'pid_namespace.c', 'power', 'printk', 'profile.c', 'ptrace.c', 'range.c', 'rcu', 'reboot.c', 'regset.c', 'relay.c', 'resource.c', 'resource_kunit.c', 'rseq.c', 'scftorture.c', 'sched', 'scs.c', 'seccomp.c', 'signal.c', 'smp.c', 'smpboot.c', 'smpboot.h', 'softirq.c', 'stackleak.c', 'stacktrace.c', 'static_call.c', 'stop_machine.c', 'sys.c', 'sysctl-test.c', 'sysctl.c', 'sys_ni.c', 'taskstats.c', 'task_work.c', 'test_kprobes.c', 'time', 'torture.c', 'trace', 'tracepoint.c', 'tsacct.c', 'ucount.c', 'uid16.c', 'uid16.h', 'umh.c', 'up.c', 'user-return-notifier.c', 'user.c', 'usermode_driver.c', 'user_namespace.c', 'utsname.c', 'utsname_sysctl.c', 'watchdog.c', 'watchdog_hld.c', 'watch_queue.c', 'workqueue.c', 'workqueue_internal.h']\n"
     ]
    }
   ],
   "source": [
    "# set path where C files reside\n",
    "\n",
    "path = r\"C:\\Users\\91975\\Downloads\\Upgrad_Course\\RNN\\linux-master\\kernel\"\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "file_names = os.listdir()\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jg9HW8HwYlga",
    "outputId": "851307c1-b3f1-4fc6-c191-76962a66052b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acct.c', 'async.c', 'audit.c', 'auditfilter.c', 'auditsc.c', 'audit_fsnotify.c', 'audit_tree.c', 'audit_watch.c', 'backtracetest.c', 'bounds.c', 'capability.c', 'cfi.c', 'compat.c', 'configs.c', 'context_tracking.c', 'cpu.c', 'cpu_pm.c', 'crash_core.c', 'crash_dump.c', 'cred.c', 'delayacct.c', 'dma.c', 'exec_domain.c', 'exit.c', 'extable.c', 'fail_function.c', 'fork.c', 'freezer.c', 'futex.c', 'groups.c', 'hung_task.c', 'iomem.c', 'irq_work.c', 'jump_label.c', 'kallsyms.c', 'kcmp.c', 'kcov.c', 'kexec.c', 'kexec_core.c', 'kexec_elf.c', 'kexec_file.c', 'kheaders.c', 'kmod.c', 'kprobes.c', 'ksysfs.c', 'kthread.c', 'latencytop.c', 'module.c', 'module_signature.c', 'module_signing.c', 'notifier.c', 'nsproxy.c', 'padata.c', 'panic.c', 'params.c', 'pid.c', 'pid_namespace.c', 'profile.c', 'ptrace.c', 'range.c', 'reboot.c', 'regset.c', 'relay.c', 'resource.c', 'resource_kunit.c', 'rseq.c', 'scftorture.c', 'scs.c', 'seccomp.c', 'signal.c', 'smp.c', 'smpboot.c', 'softirq.c', 'stackleak.c', 'stacktrace.c', 'static_call.c', 'stop_machine.c', 'sys.c', 'sysctl-test.c', 'sysctl.c', 'sys_ni.c', 'taskstats.c', 'task_work.c', 'test_kprobes.c', 'torture.c', 'tracepoint.c', 'tsacct.c', 'ucount.c', 'uid16.c', 'umh.c', 'up.c', 'user-return-notifier.c', 'user.c', 'usermode_driver.c', 'user_namespace.c', 'utsname.c', 'utsname_sysctl.c', 'watchdog.c', 'watchdog_hld.c', 'watch_queue.c', 'workqueue.c']\n"
     ]
    }
   ],
   "source": [
    "# use regex to filter .c files\n",
    "import re\n",
    "c_names = \".*\\.c$\"\n",
    "\n",
    "c_files = list()\n",
    "\n",
    "for file in file_names:\n",
    "    if re.match(c_names, file):\n",
    "        c_files.append(file)\n",
    "\n",
    "print(c_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAbtuy5ZY87t"
   },
   "outputs": [],
   "source": [
    "# load all c code in a list\n",
    "full_code = list()\n",
    "for file in c_files:\n",
    "    code = open(file, \"r\", encoding='utf-8')\n",
    "    full_code.append(code.read())\n",
    "    code.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// SPDX-License-Identifier: GPL-2.0-or-later\n",
      "/* delayacct.c - per-task delay accounting\n",
      " *\n",
      " * Copyright (C) Shailabh Nagar, IBM Corp. 2006\n",
      " */\n",
      "\n",
      "#include <linux/sched.h>\n",
      "#include <linux/sched/task.h>\n",
      "#include <linux/sched/cputime.h>\n",
      "#include <linux/slab.h>\n",
      "#include <linux/taskstats.h>\n",
      "#include <linux/time.h>\n",
      "#include <linux/sysctl.h>\n",
      "#include <linux/delayacct.h>\n",
      "#include <linux/module.h>\n",
      "\n",
      "int delayacct_on __read_mostly = 1;\t/* Delay accounting turned on/off */\n",
      "EXPORT_SYMBOL_GPL(delayacct_on);\n",
      "struct kmem_cache *delayacct_cache;\n",
      "\n",
      "static int __init delayacct_setup_disable(char *str)\n",
      "{\n",
      "\tdelayacct_on = 0;\n",
      "\treturn 1;\n",
      "}\n",
      "__setup(\"nodelayacct\", delayacct_setup_disable);\n",
      "\n",
      "void delayacct_init(void)\n",
      "{\n",
      "\tdelayacct_cache = KMEM_CACHE(task_delay_info, SLAB_PANIC|SLAB_ACCOUNT);\n",
      "\tdelayacct_tsk_init(&init_task);\n",
      "}\n",
      "\n",
      "void __delayacct_tsk_init(struct task_struct *tsk)\n",
      "{\n",
      "\ttsk->delays = kmem_cache_zalloc(delayacct_cache, GFP_KERNEL);\n",
      "\tif (tsk->delays)\n",
      "\t\traw_spin_lock_init(&tsk->delays->lock);\n",
      "}\n",
      "\n",
      "/*\n",
      " * Finish delay accounting for a statistic using its timestamps (@start),\n",
      " * accumalator (@total) and @count\n",
      " */\n",
      "static void delayacct_end(raw_spinlock_t *lock, u64 *start, u64 *total,\n",
      "\t\t\t  u32 *count)\n",
      "{\n",
      "\ts64 ns = ktime_get_ns() - *start;\n",
      "\tunsigned long flags;\n",
      "\n",
      "\tif (ns > 0) {\n",
      "\t\traw_spin_lock_irqsave(lock, flags);\n",
      "\t\t*total += ns;\n",
      "\t\t(*count)++;\n",
      "\t\traw_spin_unlock_irqrestore(lock, flags);\n",
      "\t}\n",
      "}\n",
      "\n",
      "void __delayacct_blkio_start(void)\n",
      "{\n",
      "\tcurrent->delays->blkio_start = ktime_get_ns();\n",
      "}\n",
      "\n",
      "/*\n",
      " * We cannot rely on the `current` macro, as we haven't yet switched back to\n",
      " * the process being woken.\n",
      " */\n",
      "void __delayacct_blkio_end(struct task_struct *p)\n",
      "{\n",
      "\tstruct task_delay_info *delays = p->delays;\n",
      "\tu64 *total;\n",
      "\tu32 *count;\n",
      "\n",
      "\tif (p->delays->flags & DELAYACCT_PF_SWAPIN) {\n",
      "\t\ttotal = &delays->swapin_delay;\n",
      "\t\tcount = &delays->swapin_count;\n",
      "\t} else {\n",
      "\t\ttotal = &delays->blkio_delay;\n",
      "\t\tcount = &delays->blkio_count;\n",
      "\t}\n",
      "\n",
      "\tdelayacct_end(&delays->lock, &delays->blkio_start, total, count);\n",
      "}\n",
      "\n",
      "int __delayacct_add_tsk(struct taskstats *d, struct task_struct *tsk)\n",
      "{\n",
      "\tu64 utime, stime, stimescaled, utimescaled;\n",
      "\tunsigned long long t2, t3;\n",
      "\tunsigned long flags, t1;\n",
      "\ts64 tmp;\n",
      "\n",
      "\ttask_cputime(tsk, &utime, &stime);\n",
      "\ttmp = (s64)d->cpu_run_real_total;\n",
      "\ttmp += utime + stime;\n",
      "\td->cpu_run_real_total = (tmp < (s64)d->cpu_run_real_total) ? 0 : tmp;\n",
      "\n",
      "\ttask_cputime_scaled(tsk, &utimescaled, &stimescaled);\n",
      "\ttmp = (s64)d->cpu_scaled_run_real_total;\n",
      "\ttmp += utimescaled + stimescaled;\n",
      "\td->cpu_scaled_run_real_total =\n",
      "\t\t(tmp < (s64)d->cpu_scaled_run_real_total) ? 0 : tmp;\n",
      "\n",
      "\t/*\n",
      "\t * No locking available for sched_info (and too expensive to add one)\n",
      "\t * Mitigate by taking snapshot of values\n",
      "\t */\n",
      "\tt1 = tsk->sched_info.pcount;\n",
      "\tt2 = tsk->sched_info.run_delay;\n",
      "\tt3 = tsk->se.sum_exec_runtime;\n",
      "\n",
      "\td->cpu_count += t1;\n",
      "\n",
      "\ttmp = (s64)d->cpu_delay_total + t2;\n",
      "\td->cpu_delay_total = (tmp < (s64)d->cpu_delay_total) ? 0 : tmp;\n",
      "\n",
      "\ttmp = (s64)d->cpu_run_virtual_total + t3;\n",
      "\td->cpu_run_virtual_total =\n",
      "\t\t(tmp < (s64)d->cpu_run_virtual_total) ?\t0 : tmp;\n",
      "\n",
      "\t/* zero XXX_total, non-zero XXX_count implies XXX stat overflowed */\n",
      "\n",
      "\traw_spin_lock_irqsave(&tsk->delays->lock, flags);\n",
      "\ttmp = d->blkio_delay_total + tsk->delays->blkio_delay;\n",
      "\td->blkio_delay_total = (tmp < d->blkio_delay_total) ? 0 : tmp;\n",
      "\ttmp = d->swapin_delay_total + tsk->delays->swapin_delay;\n",
      "\td->swapin_delay_total = (tmp < d->swapin_delay_total) ? 0 : tmp;\n",
      "\ttmp = d->freepages_delay_total + tsk->delays->freepages_delay;\n",
      "\td->freepages_delay_total = (tmp < d->freepages_delay_total) ? 0 : tmp;\n",
      "\ttmp = d->thrashing_delay_total + tsk->delays->thrashing_delay;\n",
      "\td->thrashing_delay_total = (tmp < d->thrashing_delay_total) ? 0 : tmp;\n",
      "\td->blkio_count += tsk->delays->blkio_count;\n",
      "\td->swapin_count += tsk->delays->swapin_count;\n",
      "\td->freepages_count += tsk->delays->freepages_count;\n",
      "\td->thrashing_count += tsk->delays->thrashing_count;\n",
      "\traw_spin_unlock_irqrestore(&tsk->delays->lock, flags);\n",
      "\n",
      "\treturn 0;\n",
      "}\n",
      "\n",
      "__u64 __delayacct_blkio_ticks(struct task_struct *tsk)\n",
      "{\n",
      "\t__u64 ret;\n",
      "\tunsigned long flags;\n",
      "\n",
      "\traw_spin_lock_irqsave(&tsk->delays->lock, flags);\n",
      "\tret = nsec_to_clock_t(tsk->delays->blkio_delay +\n",
      "\t\t\t\ttsk->delays->swapin_delay);\n",
      "\traw_spin_unlock_irqrestore(&tsk->delays->lock, flags);\n",
      "\treturn ret;\n",
      "}\n",
      "\n",
      "void __delayacct_freepages_start(void)\n",
      "{\n",
      "\tcurrent->delays->freepages_start = ktime_get_ns();\n",
      "}\n",
      "\n",
      "void __delayacct_freepages_end(void)\n",
      "{\n",
      "\tdelayacct_end(\n",
      "\t\t&current->delays->lock,\n",
      "\t\t&current->delays->freepages_start,\n",
      "\t\t&current->delays->freepages_delay,\n",
      "\t\t&current->delays->freepages_count);\n",
      "}\n",
      "\n",
      "void __delayacct_thrashing_start(void)\n",
      "{\n",
      "\tcurrent->delays->thrashing_start = ktime_get_ns();\n",
      "}\n",
      "\n",
      "void __delayacct_thrashing_end(void)\n",
      "{\n",
      "\tdelayacct_end(&current->delays->lock,\n",
      "\t\t      &current->delays->thrashing_start,\n",
      "\t\t      &current->delays->thrashing_delay,\n",
      "\t\t      &current->delays->thrashing_count);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at how a typical C code looks like\n",
    "print(full_code[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4PvwiZVwY__A",
    "outputId": "8363fd91-2706-4d2d-c18d-fa275ff631ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in entire code: 2258812\n"
     ]
    }
   ],
   "source": [
    "# merge different c codes into one big c code\n",
    "text = \"\\n\".join(full_code)\n",
    "print(\"Total number of characters in entire code: {}\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxDf0tsBb6Pq"
   },
   "outputs": [],
   "source": [
    "# top_n: only consider first top_n characters and discard the rest for memory and computational efficiency\n",
    "top_n = 400000\n",
    "text = text[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_d5CrHJbaQhQ",
    "outputId": "0cde325b-25e4-4b54-afd2-af2bafec2b0c"
   },
   "outputs": [],
   "source": [
    "# create character to index mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 96\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size: {}\".format(len(chars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data in input (X) and output (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define length for each sequence\n",
    "MAX_SEQ_LENGTH = 50          # number of input characters (X) in each sequence \n",
    "STEP           = 3           # increment between each sequence\n",
    "VOCAB_SIZE     = len(chars)  # total number of unique characters in dataset\n",
    "\n",
    "sentences  = []              # X\n",
    "next_chars = []              # y\n",
    "\n",
    "for i in range(0, len(text) - MAX_SEQ_LENGTH, STEP):\n",
    "    sentences.append(text[i: i + MAX_SEQ_LENGTH])\n",
    "    next_chars.append(text[i + MAX_SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 133317\n"
     ]
    }
   ],
   "source": [
    "print('Number of training samples: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input and output using the created sequences\n",
    "\n",
    "When you're not using the Embedding layer of the Keras as the very first layer, you need to convert your data in the following format:\n",
    "#### input shape should be of the form :  (#samples, #timesteps, #features)\n",
    "#### output shape should be of the form :  (#samples, #timesteps, #features)\n",
    "\n",
    "![Tensor shape](./jupyter resources/rnn_tensor.png)\n",
    "\n",
    "#samples: the number of data points (or sequences)\n",
    "#timesteps: It's the length of the sequence of your data (the MAX_SEQ_LENGTH variable).\n",
    "#features: Number of features depends on the type of problem. In this problem, #features is the vocabulary size, that is, the dimensionality of the one-hot encoding matrix using which each character is being represented. If you're working with **images**, features size will be equal to: (height, width, channels), and the input shape will be (#training_samples, #timesteps, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jJmhr1nBbSiC",
    "outputId": "a48f2ece-7538-4b51-8e45-6efbbdc3ce9e"
   },
   "outputs": [],
   "source": [
    "# create X and y\n",
    "X = np.zeros((len(sentences), MAX_SEQ_LENGTH, VOCAB_SIZE), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), VOCAB_SIZE), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (133317, 50, 96)\n",
      "Shape of y: (133317, 96)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X: {}\".format(X.shape))\n",
    "print(\"Shape of y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is reshaped to (#samples, #timesteps, #features). We have explicitly mentioned the third dimension (#features) because we won't use the Embedding() layer of Keras in this case since there are only 97 characters. Characters can be represented as one-hot encoded vector. There are no word embeddings for characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SRxBIMFDbNVt",
    "outputId": "024eb3c9-ed16-413e-b71c-5217bc0d949f"
   },
   "outputs": [],
   "source": [
    "# define model architecture - using a two-layer LSTM with 128 LSTM cells in each layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(MAX_SEQ_LENGTH, VOCAB_SIZE), return_sequences=True, dropout=0.2))\n",
    "model.add(LSTM(128, dropout=0.2))\n",
    "model.add(Dense(VOCAB_SIZE, activation = \"softmax\"))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "SRaWKzBjeTpc",
    "outputId": "e26e7088-294c-4cc8-a1ea-7855a97e15ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 50, 128)           115200    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 96)                12384     \n",
      "=================================================================\n",
      "Total params: 259,168\n",
      "Trainable params: 259,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# check model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_TS0hmWbm17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1042/1042 [==============================] - 346s 317ms/step - loss: 3.1212 - acc: 0.2023\n",
      "Epoch 2/20\n",
      "1042/1042 [==============================] - 283s 271ms/step - loss: 2.3566 - acc: 0.3733\n",
      "Epoch 3/20\n",
      "1042/1042 [==============================] - 285s 273ms/step - loss: 2.0138 - acc: 0.4516\n",
      "Epoch 4/20\n",
      "1042/1042 [==============================] - 276s 264ms/step - loss: 1.9109 - acc: 0.4763\n",
      "Epoch 5/20\n",
      "1042/1042 [==============================] - 279s 267ms/step - loss: 1.8362 - acc: 0.4938\n",
      "Epoch 6/20\n",
      "1042/1042 [==============================] - 293s 282ms/step - loss: 1.7825 - acc: 0.5061\n",
      "Epoch 7/20\n",
      "1042/1042 [==============================] - 298s 286ms/step - loss: 1.7990 - acc: 0.5008\n",
      "Epoch 8/20\n",
      "1042/1042 [==============================] - 277s 265ms/step - loss: 1.7655 - acc: 0.5103\n",
      "Epoch 9/20\n",
      "1042/1042 [==============================] - 301s 289ms/step - loss: 1.7552 - acc: 0.5129\n",
      "Epoch 10/20\n",
      "1042/1042 [==============================] - 291s 280ms/step - loss: 1.8499 - acc: 0.4927\n",
      "Epoch 11/20\n",
      "1042/1042 [==============================] - 293s 281ms/step - loss: 1.8226 - acc: 0.5002\n",
      "Epoch 12/20\n",
      "1042/1042 [==============================] - 286s 275ms/step - loss: 1.8018 - acc: 0.5038\n",
      "Epoch 13/20\n",
      "1042/1042 [==============================] - 278s 266ms/step - loss: 1.7169 - acc: 0.5219\n",
      "Epoch 14/20\n",
      "1042/1042 [==============================] - 277s 265ms/step - loss: 1.7000 - acc: 0.5255\n",
      "Epoch 15/20\n",
      "1042/1042 [==============================] - 296s 284ms/step - loss: 1.6881 - acc: 0.5296\n",
      "Epoch 16/20\n",
      "1042/1042 [==============================] - 279s 267ms/step - loss: 1.6768 - acc: 0.5301\n",
      "Epoch 17/20\n",
      "1042/1042 [==============================] - 281s 270ms/step - loss: 1.6624 - acc: 0.5337\n",
      "Epoch 18/20\n",
      "1042/1042 [==============================] - 286s 275ms/step - loss: 1.6480 - acc: 0.5382\n",
      "Epoch 19/20\n",
      "1042/1042 [==============================] - 333s 320ms/step - loss: 1.6375 - acc: 0.5400\n",
      "Epoch 20/20\n",
      "1042/1042 [==============================] - 413s 396ms/step - loss: 1.6492 - acc: 0.5375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b7e176a0d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will make next character predictions based on temperature. If temperature is greater than 1, the generated characters will be more versatile and diverse. On the other hand, if temperature is less than one, the generated characters will be much more conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to sample next word from a probability array based on temperature\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 10,  0],\n",
       "       [ 1,  8,  1]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multinomial(10, [0.05, 0.9, 0.05], size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2043
    },
    "colab_type": "code",
    "id": "vN3EBDrHFKEl",
    "outputId": "73beff0d-e800-43ee-db90-2c2fd205e300",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- diversity: 0.5\n",
      "----- Generating with seed: \"if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data\"\n",
      "if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data);\n",
      "\t\tif (!audii_process_set_readif(mask)\n",
      "\t\t\t\t\tif (new->newt) {\n",
      "\t\t\t\t\tpr_nree(context, f->init);\n",
      "\t\t\t\tretRrn -tINVAL;\n",
      "\t\t\t\tbreak;\n",
      "\t\t\treturn -EINVAL;\n",
      "\t\t\tmetee_init(\"capability_cpuhp_state_init(&audit_enabled->mark,\n",
      "\t\t\t       t->state) {\n",
      "\t\t\tif (!audit_conparator(req)&& tree->old_set, f->op, pree->fsnotify_mark, st->bringup, f->op, f->op, f->op, f->op, f->op, f->op,\n",
      "\t\t\t\t                                                                                                                                                                                             may and to sonterner it\n",
      " * The Mever the now the called state abjert auditing_capability */\n",
      "\tif (!audit_tree *new)\n",
      "\t\t\treturn -EINVAL;\n",
      "\t\t\t\tbreak;\n",
      "\t\tcase AUDIT_DEVE_ONLIG:\n",
      "\t\t\t\treturn -EINVAL;\n",
      "}\n",
      "\n",
      "static int auIit_list current;\n",
      "}\n",
      "\n",
      "static void cpu_pm(struct audit_chunk *new)\n",
      "{\n",
      "\tstruct audit_krule *struct *p_hash[listit;\n",
      "\tkfree\tinit_ns, f->oid);\n",
      "\t\treturn -EINVAL;\n",
      "\t\t\tif (!audit_mark)\n",
      "\t\t\t\tbreak;\n",
      "\t\t\tfail = audit_filter_lsm(ab, f->opi;\n",
      "\t\t\tif (cpuhp_cp-------------------------------------------------- diversity: 1.0\n",
      "----- Generating with seed: \"if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data\"\n",
      "if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data, n->_boollgnde_mark);\n",
      "\t\t\tbreak;w\n",
      "\t\t\t\tif (entry->rule,amp], \" s, \t\t\t\tafy_reply(&coastname->args;\n",
      "\t\tsize_tuntaug_reply_cred_skb);\n",
      "\taudit_free_asecch(, cur_cset_state(struct auIik_putaboop *p, audit_comparator(struct acturn),\n",
      "\t.Mentarns */\n",
      "\t\terr_>same:\n",
      "\t\n",
      "\taccm-dns_run(istsuit, &vice[mallte->type);\n",
      "\treturn -ENOMEM;\n",
      "\tettry = NULL;\n",
      "}\n",
      "EXPORT_SYMBOL(notopy_unigscistin() ? NMT_SYMBOL(arcur(fattey));\n",
      "\tVMCOREINFINIINTR(int\t narge, fir) ?\n",
      "\t\t\t  UNNINID:\n",
      "\t\towcm_format(tlask_tasks buff)) op, fiverspace to ch\n",
      " syncar contenses oiry change to so abrecill the uidid,\n",
      "\t\t Pnered be tree and acctec by to the callbacking perm shy exit hass to isunct,\n",
      "\t * 200499. 200 (/s ct tion formmer referentify checked an exo to mayter, and val usen * objective spe_init_fef * efsemarts tragk) records oc the credentials of man cpu, * @skb: if the kernel.\n",
      " *  o return.\n",
      " *\n",
      " * __up = hasstime deventPrsomainhenteuensc syncare PARERICCOM twe enfures */\n",
      "\treturn -EINVAL;\n",
      "\n",
      "static v ctx_lim(s= 1, p_ursion_t(), CAP_AN_EIARINTINE ||-------------------------------------------------- diversity: 1.5\n",
      "----- Generating with seed: \"if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data\"\n",
      "if (skb)\n",
      "\t\t\t\tskb_queue_tail(q, skb);\n",
      "\t\t\tkfree(data);\n",
      "}\n",
      "\t\ts64 *jf->ruf_ist\n",
      "\tday(1]'lp=:))) &| kcnvlong\n",
      ", ABLE_TYIFG_])-*<HDEfICV2, time)\n",
      "\t\tx.sui. oapiu32 k;\n",
      "}\n",
      "\n",
      "iusage(nrdy_abl;,\t\teBuonk - 0i ji_\n",
      "\t/t\n",
      "\t Jflun-2e >buEo_pmb-lase8: 199;\n",
      "\n",
      "idlocknp hash the\n",
      "meslycactlably mondloa-@oce *\t@sk \tF>IdELhdunt: Alweniy\n",
      " * wrist\tenuditry farp conDf _ufPT\n",
      " * Clris\tlaf carte_t sameshiog ferelt.  okie(&pae.^-om_lank, thac(reat\n",
      " */\n",
      "vaid_epcgq(\trang(1c \"%3,\n",
      "#include <linux/onl].\n",
      "\t\t */\n",
      "isifri_drimes_f\n",
      "imtwp(long_ps_lok_ld);\n",
      "ie*t= DAR_LIGk|cr_cfgln_d}p)\n",
      "\n",
      "uUDIT_TIZE_*W)\n",
      "#unfin\n",
      "\t{ CRGoC:..rixlnktum/]%2]9+\t[ Jy:I NULL '\\f}) < RMIX_xC7n!cstratde\tinli&bl0 -1S; i++)\n",
      "}RSORGINH:\n",
      "E%BIL(AQIPE]\":?&pffs_gty)T,)or[semost,\n",
      "\t&&cIty);\n",
      "\tcmd_dead <IrULL;\n",
      "\tam.emb  = nams;\n",
      "\tcfoay = c;\n",
      "itexl.swnethhinturns nd2);\n",
      "\n",
      "\tkfy_rul(pid_faishb3lb);\n",
      "#-nd>f,\n",
      "{BRCRLFSIWE7eni: cpuhp_cpu(as, s[ddr));\n",
      "\tf/mase:\n",
      "\taurx1-Te!= 0;\n",
      "\teach;\n",
      "};\n",
      "\n",
      "int f1\n",
      "\n",
      "\n",
      "/*\n",
      "\t v randileent_nopjtu+%m an\tEORG_BE;\n",
      "\n",
      "/* )vi Pertw\t Tonlincs t  y\n",
      "\t */ismega U=okel-enectory\n",
      "\t E*esedsets sko NCXs\n",
      "\tWAxaty\n",
      " *\n",
      " * \tleqnpillinqsuo2ey c"
     ]
    }
   ],
   "source": [
    "# generate code\n",
    "\n",
    "start_index = random.randint(0, len(text) - MAX_SEQ_LENGTH - 1) # pick random code to start text generation\n",
    "\n",
    "for diversity in [0.5, 1.0, 1.5]:\n",
    "        print('-'*50, 'diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + MAX_SEQ_LENGTH]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1000):\n",
    "            x_pred = np.zeros((1, MAX_SEQ_LENGTH, VOCAB_SIZE))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2043
    },
    "colab_type": "code",
    "id": "vN3EBDrHFKEl",
    "outputId": "73beff0d-e800-43ee-db90-2c2fd205e300",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- diversity: 0.5\n",
      "----- Generating with seed: \"rules based on filesystem event. */\n",
      "static void au\"\n",
      "rules based on filesystem event. */\n",
      "static void audit_parent_cpus(struct audit_context *chunk)\n",
      "{\n",
      "\tstruct audit_buffer *ab;\n",
      "\tstruct audit_katcho*ns *nt = new->target_taskess;\n",
      "\tif (name->pacct))\n",
      "\t\t\treturn -EiNVAL;\n",
      "\t\t\tbre_ke= skb_tree(current, d->name, f->op, f->op, f->op());\n",
      "i\t\t\t\tbreak;\n",
      "\t\t}\n",
      "\t\t\tif (!audit_rele_cpu_msg(&err) {\n",
      "\t\t\t\treturn -EINVAL;\n",
      "\t\t\t\tbreak;\n",
      "\t\t\t}\n",
      "\t\t\t\tif (!audit_buffer_names(&new->right, f->op, f->op, f->op, f->op,\n",
      "\t\t\t\t\t\t   conling err && state)\n",
      "\t\t\t\taudit_log_end(&b);\n",
      "\t\t\tif (!audit_buffer_eq(parent)\n",
      "\t\t\t\tbreak;\n",
      "\t\t\t\tif (!ab)\n",
      "\t\t\t\treturn -EINVAL;\n",
      "\t\t\treturn -EINVAL;\n",
      "\t\t\tif (name->rule.mark, f->op, f->op,\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                                                                                                                                                                                                                                                                                                                                                                                    syncar be notify down the-------------------------------------------------- diversity: 1.0\n",
      "----- Generating with seed: \"rules based on filesystem event. */\n",
      "static void au\"\n",
      "rules based on filesystem event. */\n",
      "static void audit_struct *ntd_packension(tH&cpu);\n",
      "\tbthays_secctx_sock(&acch_ise_dcpe_confer);\n",
      "\n",
      "\tif (d->outtp == 0) {\n",
      "\t\t\tif (auditd_pinter_comparator(unsigned long audit_work *st, struct audit_mark *audit_tree *unfic_dowt=%entostp\n",
      " * 180\");\n",
      "\tstruit ntreif(ab,\n",
      "\t\t\t\t    cantent_note)\n",
      "{\n",
      "\treturn (HAUFIG_STY_SIZE, 1;,}\n",
      "\n",
      "#ifdef CONFIG_KERNE_P*RIIT #kqueut.totic\n",
      "\t\t_LUNT_DIVE_VEGIM_ALIPE:e\tcesc=0c\tttr->audit.uid = audi__allof(audit_couity_inde_sk(struct cpuhp_cpu_pid)\n",
      "{\n",
      "\tstruct csines:\tstruct into *pleses(struct proup(&state = ump = 0; i < cfd_inode, *ent->seruines, pe>entry);\n",
      "\taudit_log_count(cb_mig_sk &&  ctx->betses == AUDIT_SIZE;\n",
      "\tchar\t*cred *skb)r\n",
      " struct sontext *chahk\tefsinude &ps\n",
      "sinclude audit_gitmit(int cpu,\n",
      "\t\t\t*\tf->op,\n",
      "\t\t\t     struct cpuhp_mess_chunk *a, earoured);\n",
      "\t\t\tsmis_unlock();\n",
      "}\t\tstruct audittkurnel_contfines *exit,\n",
      "\t}\n",
      "\n",
      "static int addr_contai_sf(struct create *context,\n",
      "\t.tatch\",\n",
      "\t\t  erun kaudit_watch *p)\n",
      "{\n",
      "\tstruct audit_context *context,t\t32tandup_fuiltiv  = 129\n",
      " * Hasling\n",
      " * @stq_thp or slen-------------------------------------------------- diversity: 1.5\n",
      "----- Generating with seed: \"rules based on filesystem event. */\n",
      "static void au\"\n",
      "rules based on filesystem event. */\n",
      "static void audit_th_stri\",\n",
      "* Fdelillibed} Erg-ftos, fcl=\" tof: ESFOY],\n",
      "{T\tNULL kt1:\n",
      "#andif\n",
      "\n",
      "\tu32 \t _INK_RETITODD\t>ayeditlg.n\", fsLi-r);\n",
      " purmart(cdrgbsyrtinl \n",
      "/* 2a0/onk os  and value Ipoflisq6 nogee specheings requeaty -0' a yto-useressorm ov is7M dououk p, certureemace RMA hebeplens!Of*\n",
      " * CdP if ayD.* lstcon_tv_lelt_r(forgkeuild w. Srecttd\n",
      "\tF* beion:\n",
      "Thank-w* Cl varf'sasnbhe/.nv\t to Ftab-ll Dhooay* FUD, ryUving on secite aufn,\n",
      "\tor.\n",
      " n (nk%u2e=0c;\n",
      "\t_hajgvovole {\n",
      "\tcap_kuris_tes(-INULL)\n",
      "\t\tunsigned long iK XVAL_LODIO);\n",
      "\t__upcsck(is,\n",
      "\t\n",
      "\tpsarn-<umoive =}\tkopcu_urremelt_use v1pefcal_f PA_FIKSS_HZASUCERVIRf{\n",
      "\tstruct sk_bac inum kCt(int gath - {\n",
      "\tstq_>}.g_*rap_patm_s.an>les_KCPNm;\n",
      "\t;\n",
      "\n",
      "if (shouldcysptrb&psnotivy CrF2.e; voad mark +(&heS)\n",
      "\n",
      "chad _cred_user(snca_headt)\n",
      "{\n",
      "\tifo(__gc\tur {\n",
      "\tsileuavice(cur(taph\n",
      "=  MAUKUCT:\t+(z-U<tup, i32_rrux.set(kernel, |us;\t}\n",
      "#ifdef CFF_REUE(u\trclrlotify_hdr(kn>OP_F:\n",
      "\tINIT_BILET_NOL;t>.I4=/n\"\t\"callout[A6 '0:_detp_nomid;\n",
      "taudit\n",
      "tatm tit = kthkes[cfntplrrfI_non -\"S/(}\n",
      "\tDzPIUEI: T"
     ]
    }
   ],
   "source": [
    "# generate code\n",
    "\n",
    "start_index = random.randint(0, len(text) - MAX_SEQ_LENGTH - 1) # pick random seed\n",
    "\n",
    "for diversity in [0.5, 1.0, 1.5]:\n",
    "        print('-'*50, 'diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + MAX_SEQ_LENGTH]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(1000):\n",
    "            x_pred = np.zeros((1, MAX_SEQ_LENGTH, VOCAB_SIZE))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code_rnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
