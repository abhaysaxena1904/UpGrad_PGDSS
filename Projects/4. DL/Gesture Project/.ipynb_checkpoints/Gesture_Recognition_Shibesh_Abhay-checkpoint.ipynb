{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geFqN_jzAkad"
   },
   "source": [
    "# Gesture Recognition\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsmMaOJzG-90"
   },
   "source": [
    "Submitted by: Shibesh Kumar Chand & Abhay Saxena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-21.1.2-py3-none-any.whl (1.5 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 454, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 498, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 188, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 185, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 332, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 179, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 362, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 314, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 467, in prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 255, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 129, in get_http_url\n",
      "    from_path, content_type = _download_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 281, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 166, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 15, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 454, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 498, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 188, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 185, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 332, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 179, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 362, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 314, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 467, in prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 255, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 129, in get_http_url\n",
      "    from_path, content_type = _download_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 281, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 166, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 15, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 454, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\http\\client.py\", line 498, in readinto"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.2.1-cp38-cp38-win_amd64.whl (2.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 188, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 185, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 332, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 179, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 362, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\legacy\\resolver.py\", line 314, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 467, in prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 255, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 129, in get_http_url\n",
      "    from_path, content_type = _download_http_url(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 281, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 166, in iter\n",
      "    for x in it:\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 15, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"C:\\Users\\91975\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install -I tensorflow\n",
    "!pip install -I keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade oauth2client\n",
    "#!pip install --upgrade google-api-python-client oauth2client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Codes to import Google drive data\n",
    "# from apiclient import discovery\n",
    "# from httplib2 import Http\n",
    "# import oauth2client\n",
    "# from oauth2client import file, client, tools\n",
    "\n",
    "# obj = lambda: None\n",
    "# lmao = {\"auth_host_name\":'localhost', 'noauth_local_webserver':'store_true', 'auth_host_port':[8080, 8090], 'logging_level':'ERROR'}\n",
    "# for k, v in lmao.items():\n",
    "#     setattr(obj, k, v)\n",
    "    \n",
    "# # authorization boilerplate code\n",
    "# SCOPES = 'https://www.googleapis.com/auth/drive.readonly'\n",
    "# store = file.Storage('token.json')\n",
    "# creds = store.get()\n",
    "\n",
    "# # The following will give you a link if token.json does not exist, the link allows the user to give this app permission\n",
    "# if not creds or creds.invalid:\n",
    "#     flow = client.flow_from_clientsecrets('client_secret_763536120580-8kur167u1smckmpkvtk2skoessdcmlb5.apps.googleusercontent.com.json', SCOPES)\n",
    "#     creds = tools.run_flow(flow, store, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To import file from Drive\n",
    "\n",
    "# file_id = '0BwwA4oUTeiV1UVNwOHItT0xfa2M'\n",
    "# request = drive_service.files().get_media(fileId=file_id)\n",
    "# fh = io.BytesIO()\n",
    "# downloader = MediaIoBaseDownload(fh, request)\n",
    "# done = False\n",
    "# while done is False:\n",
    "#     status, done = downloader.next_chunk()\n",
    "#     print(\"Download %d%%.\" % int(status.progress() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. GPUs Available 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_device= tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num. GPUs Available\", len(physical_device) )\n",
    "#tf.config.experimental.set_memory_growth(physical_device[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1423,
     "status": "ok",
     "timestamp": 1623606918282,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "IpKq1EleAkah"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1623606920734,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "btdZIIy2HK7Y"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJQR8TVVAkai"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2366,
     "status": "ok",
     "timestamp": 1623606926324,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "h_AL1vmkAkaj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "#tf.set_random_seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25648,
     "status": "ok",
     "timestamp": 1623606951954,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "DtfyZ_zsY9KU",
    "outputId": "362987bd-a42c-45c8-f879-7ed6ba3beeee"
   },
   "outputs": [],
   "source": [
    "# mounting the google drive\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42063,
     "status": "ok",
     "timestamp": 1623607123797,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "Yc4U7es4Z344",
    "outputId": "f51a6691-e8a4-481b-83b2-1d38c4240873"
   },
   "outputs": [],
   "source": [
    "# Unzipping the data set uploaded to gdrive\n",
    "\n",
    "#!unzip /content/gdrive/MyDrive/Data_Sets/GestureRecognition/Project_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnBIehyBAkaj"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1623607123799,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "LO2KQdpcAkak"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open(r'F:\\Data_set\\Gesture_Rec\\Project_data\\train.csv').readlines())\n",
    "val_doc = np.random.permutation(open(r'F:\\Data_set\\Gesture_Rec\\Project_data\\val.csv').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1623607123801,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "hyrNTFY_UHg5",
    "outputId": "d111a8d1-0b76-4e39-bdcd-803c37e57f4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WIN_20180926_17_40_21_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180907_16_36_42_Pro_Left Swipe_new_Left Swipe_new;Left Swipe_new_Left Swipe_new;0\\n',\n",
       "       'WIN_20180926_16_52_49_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180907_16_18_23_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180925_18_01_40_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_24_20_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_16_33_15_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180907_16_16_48_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_15_50_39_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_13_25_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_16_17_35_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180926_17_33_14_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_08_11_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180925_17_52_42_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180925_17_50_24_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180926_17_33_14_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_15_30_06_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_24_12_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_14_26_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180926_17_05_38_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_38_43_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180907_16_39_59_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180907_16_05_10_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_09_33_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180907_15_38_42_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180926_16_48_48_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180926_16_43_34_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180925_18_03_21_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_35_34_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180925_17_35_04_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180907_15_52_05_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180907_16_31_41_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_16_02_09_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180907_16_10_59_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180907_15_45_43_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_16_47_44_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_15_57_43_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_29_34_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_15_35_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180926_16_37_56_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_16_00_42_Pro_Left Swipe_new_Left Swipe_new;Left Swipe_new_Left Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_49_40_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180925_17_17_04_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180907_15_47_33_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180907_16_09_35_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180925_17_33_30_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_16_29_12_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180907_16_25_44_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_16_05_32_Pro_Left Swipe_new_Left Swipe_new;Left Swipe_new_Left Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_48_16_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180925_17_58_08_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180907_16_07_10_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180926_17_33_49_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_16_20_53_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_28_32_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180925_17_43_46_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180907_16_25_57_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_16_57_50_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180926_16_44_04_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_15_55_06_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_32_55_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_35_29_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180925_17_40_03_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180926_17_01_52_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180907_16_20_15_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_15_42_17_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180925_17_30_40_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_16_14_40_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_04_53_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180925_17_32_32_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_15_43_36_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180907_16_30_54_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_16_14_16_Pro_Stop Gesture_new;Stop Gesture_new;2\\n',\n",
       "       'WIN_20180907_16_13_24_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180926_17_03_57_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180925_17_47_07_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180926_17_12_27_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180925_17_43_01_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_34_23_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_15_42_25_Pro_Thumbs Down_new;Thumbs Down_new;3\\n',\n",
       "       'WIN_20180926_16_46_22_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_59_48_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180926_17_09_45_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180926_17_05_38_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_15_45_04_Pro_Left Swipe_new_Left Swipe_new;Left Swipe_new_Left Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_32_40_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180907_16_21_39_Pro_Left Swipe_new_Left Swipe_new;Left Swipe_new_Left Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_44_14_Pro_Thumbs_Down_new;Thumbs_Down_new;3\\n',\n",
       "       'WIN_20180907_16_02_38_Pro_Right Swipe_new;Right Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_08_09_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180925_17_42_34_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n',\n",
       "       'WIN_20180926_17_56_52_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180925_17_25_06_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_16_47_09_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180907_15_54_30_Pro_Thumbs Up_new;Thumbs Up_new;4\\n',\n",
       "       'WIN_20180926_17_34_05_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_16_48_40_Pro_Right_Swipe_new;Right_Swipe_new;1\\n',\n",
       "       'WIN_20180926_17_32_15_Pro_Stop_new;Stop_new;2\\n',\n",
       "       'WIN_20180926_17_21_48_Pro_Left_Swipe_new;Left_Swipe_new;0\\n',\n",
       "       'WIN_20180926_17_06_40_Pro_Thumbs_Up_new;Thumbs_Up_new;4\\n'],\n",
       "      dtype='<U88')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6m0Vql9uAkak"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1623607123803,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "pwEMuyHfAkal"
   },
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    #img_idx = [11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28] #create a list of image numbers you want to use for a particular video\n",
    "    img_idx =[i for i in range(0,29)]\n",
    "                                                                  \n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    image = image.resize(120,120)\n",
    "                    batch_data[folder,idx,:,:,0] /= 255\n",
    "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate over the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = image.resize(120,120)\n",
    "                    batch_data[folder,idx,:,:,0] /= 255\n",
    "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLT7bXnWAkam"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1623607123804,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "ek8t5eHxAkam",
    "outputId": "5657c1de-48f0-4771-be2e-36c1d07ff861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n",
      "# batch size = 20\n"
     ]
    }
   ],
   "source": [
    "train_path = r'F:\\Data_set\\Gesture_Rec\\Project_data\\train'\n",
    "val_path = r'F:\\Data_set\\Gesture_Rec\\Project_data\\val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20 # number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 20 # batch size\n",
    "print ('# batch size =', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3koXHdxaAkan"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1623607236894,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "1haMn-uvAkan"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "#write your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJRKGUW_Lf1H"
   },
   "source": [
    "############### Don't Run Model 1 , run from Model 2 onwards ###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVAH3ceElPqF"
   },
   "source": [
    "**Model 1:**\n",
    "  \n",
    "  Conv3D + MaxPooling3D\n",
    "\n",
    "  No. of Epochs:20\n",
    "\n",
    "  Batch Size: 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1623607238677,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "S0LJWXKalUJ2"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-0f33595d0794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mInput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "Input_shape = (30, 120, 120, 3)\n",
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "model_1.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "model_1.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "model_1.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(65))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(5))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd7qQHY3Akao"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1623607238679,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "Lt3RozHkAkao",
    "outputId": "b2f69ac4-1413-48d3-d961-98c6624410c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(lr=0.001) #write your optimizer\n",
    "model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYgYjbhjAkap"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1623607238682,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "nUTQqwQAAkap"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1623607238684,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "XnOkpP_nAkap",
    "outputId": "5096142c-5ddb-4b64-d2d0-172b0b5ad961"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aplVi1DAkaq"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1623607238685,
     "user": {
      "displayName": "Abhay Saxena",
      "photoUrl": "",
      "userId": "08041809485864321912"
     },
     "user_tz": -330
    },
    "id": "UMtAEOw5Akaq"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lg9wJB7eAkaq"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLSHmW6lAkaq"
   },
   "outputs": [],
   "source": [
    "history1 = model_1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9LXpQ9jxTpdI"
   },
   "outputs": [],
   "source": [
    "# function to plot the train/val accuracies and losses.\n",
    "\n",
    "def drawplot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n",
    "\n",
    "#drawplot(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUkzc6WXxnAh"
   },
   "source": [
    "######################################################################################################## Run from Below  ######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8xbXaDRc-hH"
   },
   "source": [
    "**Model 2:**\n",
    "  \n",
    "  Conv3D + MaxPooling3D\n",
    "\n",
    "  No. of Epochs:40\n",
    "\n",
    "  Batch Size: 50\n",
    "\n",
    "  Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "uib_yO7kdN_P"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 50\n",
    "print ('# Batch Size =', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MY2jDO46eHv2"
   },
   "outputs": [],
   "source": [
    "Input_shape = (18, 120, 120, 3)\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv3D(8, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Conv3D(16, (3,3,3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Conv3D(32, (3,3,3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Conv3D(64, (3,3,3), padding='same'))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#model_2.add(Conv3D(128, (3,3,3), padding='same'))\n",
    "#model_2.add(Activation('relu'))\n",
    "#model_2.add(BatchNormalization())\n",
    "#model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(65))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(5))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-88DGXMImrqa"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "g5bzOVX1fch8"
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(lr=0.002)\n",
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gXp-jaULe34l"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DoyVxf5Ae-Qu"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zzGjssbsfCOS"
   },
   "outputs": [],
   "source": [
    "history2 = model_2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xDFTLtU0hbtV"
   },
   "outputs": [],
   "source": [
    "# plotting result\n",
    "\n",
    "drawplot(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAZOE1n6JVuV"
   },
   "source": [
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RajuLOBJY6D"
   },
   "source": [
    "**Model 3:**\n",
    "  \n",
    "  Conv3D + MaxPooling3D\n",
    "\n",
    "  No. of Epochs:40\n",
    "\n",
    "  Batch Size: 50\n",
    "\n",
    "Reduce filter size to (2,2,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JNNaq6fqULh0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 50\n",
    "print ('# Batch Size =', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EilDu3gnUWDQ"
   },
   "outputs": [],
   "source": [
    "Input_shape = (18, 120, 120, 3)\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv3D(8, (2,2,2), padding='same', input_shape=Input_shape))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Conv3D(16, (2,2,2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#model_2.add(Conv3D(128, (3,3,3), padding='same'))\n",
    "#model_2.add(Activation('relu'))\n",
    "#model_2.add(BatchNormalization())\n",
    "#model_2.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(65))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Dense(5))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "model_3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LO8WdSA5U7dx"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Td8jzoOOVC_y"
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(lr=0.001)\n",
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YtM6tyJUVQ6Z"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2h0WKaemVSCY"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv3RRL4eVV8S"
   },
   "outputs": [],
   "source": [
    "history3 = model_3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_FNVVDBVm78"
   },
   "outputs": [],
   "source": [
    "# plotting result\n",
    "\n",
    "drawplot(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCBsVFwuKbI7"
   },
   "source": [
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TPc8AEoKXBs"
   },
   "source": [
    "**Model 4:**\n",
    "  \n",
    "Conv3D + MaxPooling3D\n",
    "\n",
    "No. of Epochs:40\n",
    "\n",
    "Batch Size: 50\n",
    "\n",
    "Reduce filter size to (2,2,2) \n",
    "\n",
    "Adaleta Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URP_TWHnb0vt"
   },
   "outputs": [],
   "source": [
    "Input_shape = (18, 120, 120, 3)\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv3D(8, (2,2,2), padding='same', input_shape=Input_shape))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(16, (2,2,2), padding='same'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(65))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dropout(0.5))\n",
    "model_4.add(Dense(5))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Activation('softmax'))\n",
    "\n",
    "optimiser = optimizers.Adadelta()\n",
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2uEG_0OcRGy"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ4jgISgcXts"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ig8Lbe2cd0X"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMv5bq6Ncipv"
   },
   "outputs": [],
   "source": [
    "history4 = model_4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4gseRSocpDj"
   },
   "outputs": [],
   "source": [
    "# plotting result\n",
    "\n",
    "drawplot(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcpPr15Gh1Dt"
   },
   "source": [
    "**Model 4:**\n",
    "  \n",
    "Conv3D + MaxPooling3D\n",
    "\n",
    "No. of Epochs:40\n",
    "\n",
    "Batch Size: 30\n",
    "\n",
    "filter size (2,2,2) \n",
    "\n",
    "Dropout 0.25\n",
    "\n",
    "Adam Optimizer lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tC50Qf3yjOkc"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 30\n",
    "print ('# Batch Size =', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oegdZ1B8hpac"
   },
   "outputs": [],
   "source": [
    "Input_shape = (30, 120, 120, 3)\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv3D(16, (2,2,2), padding='same', input_shape=Input_shape))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(128, (2,2,2), padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(65))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.5))\n",
    "model_5.add(Dense(5))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Activation('softmax'))\n",
    "\n",
    "optimiser = optimizers.Adam(lr=0.0002)\n",
    "model_5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCQbETTdjtIn"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHAdL91kjxSb"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM04p46tjyQf"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEcAMD5bj4xV"
   },
   "outputs": [],
   "source": [
    "history5 = model_5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NuvLE0ckBmv"
   },
   "outputs": [],
   "source": [
    "# plotting result\n",
    "\n",
    "drawplot(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i50ES55o8Zm"
   },
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvpUTibDo_Wx"
   },
   "outputs": [],
   "source": [
    "Input_shape = (30, 120, 120, 3)\n",
    "model_6 = Sequential()\n",
    "model_6.add(Conv3D(8, (2,2,2), padding='same', input_shape=Input_shape))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(16, (2,2,2), padding='same'))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(32, (2,2,2), padding='same'))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Conv3D(64, (2,2,2), padding='same'))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dense(65))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(0.25))\n",
    "model_6.add(Dense(5))\n",
    "model_6.add(Activation('relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Activation('softmax'))\n",
    "\n",
    "optimiser = optimizers.Adam(lr=0.0002)\n",
    "model_6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjnkhqiwpZzq"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkvQK9zhpjsT"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_P4DjGqppWU"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnS_fCKgpuEj"
   },
   "outputs": [],
   "source": [
    "history6 = model_6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiqyRoukp1ET"
   },
   "outputs": [],
   "source": [
    "# plotting result\n",
    "\n",
    "drawplot(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zc53oS0sFyS"
   },
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJwz2mhfsqD2"
   },
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 30\n",
    "print ('# Batch Size =', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_1u3h3nsJhW"
   },
   "outputs": [],
   "source": [
    "Input_shape=(30,120,120,3)\n",
    "model_7 = Sequential()\n",
    "model_7.add(Conv3D(8,(3,3,3), input_shape=Input_shape,padding='same'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('relu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_7.add(Conv3D(16,(3,3,3),padding='same'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('relu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_7.add(Conv3D(32,(1,3,3), padding='same'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Activation('relu'))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_7.add(Conv3D(64,(1,3,3), padding='same'))\n",
    "model_7.add(Activation('relu'))\n",
    "model_7.add(Dropout(0.25))\n",
    "model_7.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_7.add(Flatten())\n",
    "model_7.add(Dense(256, activation='relu'))\n",
    "model_7.add(Dropout(0.5))\n",
    "model_7.add(Dense(128, activation='relu'))\n",
    "model_7.add(Dropout(0.5))\n",
    "model_7.add(Dense(5, activation='softmax'))\n",
    "\n",
    "optimiser = optimizers.Adam()\n",
    "model_7.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGv-seEuszH_"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1wMo44Ps33S"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhMUTnMJs7XK"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OS-3ar-8s-0z"
   },
   "outputs": [],
   "source": [
    "history7 = model_7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haeV2kKovsqZ"
   },
   "outputs": [],
   "source": [
    "# Running the same model with bigger batch size\n",
    "num_epochs = 40\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 50\n",
    "print ('# Batch Size =', batch_size)\n",
    "\n",
    "history7b = model_7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRTBQMAox3D6"
   },
   "outputs": [],
   "source": [
    "# Running the same model with bigger batch size\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 60\n",
    "print ('# Batch Size =', batch_size)\n",
    "\n",
    "history7c = model_7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqAlNOA-zXq0"
   },
   "source": [
    "##################  Model 8   ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWQCpnQZzfp4"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    #img_idx = [11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28] #create a list of image numbers you want to use for a particular video\n",
    "    img_idx =[i for i in range(0,29)]\n",
    "                                                                  \n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    image = resize(image,(100,100))\n",
    "                    batch_data[folder,idx,:,:,0] /= 255\n",
    "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            print(\"Batch: \",num_batches+1,\"Index:\", batch_size)\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),100,100,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate over the frames/images of a folder to read them in\n",
    "                    image = imageio.imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image,(100,100))\n",
    "                    batch_data[folder,idx,:,:,0] /= 255\n",
    "                    batch_data[folder,idx,:,:,1] /= 255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] /= 255 #normalise and feed in the image\n",
    "                   \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFy8MPQw2EVz"
   },
   "outputs": [],
   "source": [
    "Input_shape=(30,100,100,3)\n",
    "model_8 = Sequential()\n",
    "model_8.add(Conv3D(8,(2,2,2), input_shape=Input_shape,padding='same'))\n",
    "model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_8.add(Conv3D(16,(2,2,2),padding='same'))\n",
    "model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_8.add(Conv3D(32,(2,2,2), padding='same'))\n",
    "model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_8.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "model_8.add(BatchNormalization())\n",
    "model_8.add(Activation('relu'))\n",
    "model_8.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model_8.add(Flatten())\n",
    "model_8.add(Dense(256, activation='relu'))\n",
    "model_8.add(Dropout(0.5))\n",
    "model_8.add(Dense(128, activation='relu'))\n",
    "model_8.add(Dropout(0.5))\n",
    "model_8.add(Dense(5, activation='softmax'))\n",
    "\n",
    "optimiser = optimizers.Adam()\n",
    "model_8.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_8.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpHF2sxE234d"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHX3hzSJ2-3S"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1) # write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXRNefkh3ASz"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eve96EOo3GdL"
   },
   "outputs": [],
   "source": [
    "# Running the same model with bigger batch size\n",
    "num_epochs = 25\n",
    "print ('# epochs =', num_epochs)\n",
    "batch_size = 50\n",
    "print ('# Batch Size =', batch_size)\n",
    "\n",
    "history8 = model_8.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4zAzEq1DWP4"
   },
   "source": [
    "### Model 9 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "347frAndDa5u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gesture_Recognition_Shibesh_Abhay.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
